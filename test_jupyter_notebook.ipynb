{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import sum \n",
    "from numpy import matmul\n",
    "from numpy import multiply\n",
    "from numpy import dot\n",
    "from numpy import exp\n",
    "from numpy import log\n",
    "from numpy import abs\n",
    "from numpy import min\n",
    "from numpy import transpose\n",
    "from numpy.core.function_base import linspace\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "import time\n",
    "\n",
    "#Loading in the MNIST data\n",
    "file = loadmat('/Users/samsuidman/Desktop/neurophysics/machine_learning/mnistAll.mat') \n",
    "\n",
    "#Preparing the data\n",
    "train_images = file['mnist']['train_images'][0][0]\n",
    "train_labels = file['mnist']['train_labels'][0][0].transpose()[0]\n",
    "test_images = file['mnist']['test_images'][0][0]\n",
    "test_labels = file['mnist']['test_labels'][0][0].transpose()[0]\n",
    "indices_3 = np.where(train_labels==3)[0]\n",
    "indices_7 = np.where(train_labels==7)[0]\n",
    "indices_3_test = np.where(test_labels==3)[0]\n",
    "indices_7_test = np.where(test_labels==7)[0]\n",
    "X3 = train_images[:,:,indices_3]\n",
    "X7 = train_images[:,:,indices_7]\n",
    "X3_test = test_images[:,:,indices_3_test]\n",
    "X7_test = test_images[:,:,indices_7_test]\n",
    "n3 = np.size(X3,2)\n",
    "n7 = np.size(X7,2)\n",
    "n3_test = np.size(X3_test,2)\n",
    "n7_test = np.size(X7_test,2)\n",
    "X3 = np.reshape(X3,[784,n3])\n",
    "X7 = np.reshape(X7,[784,n7])\n",
    "X3_test = np.reshape(X3_test,[784,n3_test])\n",
    "X7_test = np.reshape(X7_test,[784,n7_test])\n",
    "X3 = X3/np.max((np.max(np.concatenate(X3)),np.max(np.concatenate(X7))))\n",
    "X7 = X7/np.max((np.max(np.concatenate(X3)),np.max(np.concatenate(X7))))\n",
    "X3_test = X3_test/np.max((np.max(np.concatenate(X3_test)),np.max(np.concatenate(X7_test))))\n",
    "X7_test = X7_test/np.max((np.max(np.concatenate(X3_test)),np.max(np.concatenate(X7_test))))\n",
    "X3 = (np.insert(X3,0,1,axis=0)).transpose() #shape = (6131,785)\n",
    "X7 = (np.insert(X7,0,1,axis=0)).transpose() #shape = (6265,785)\n",
    "X3_test = (np.insert(X3_test,0,1,axis=0)).transpose() #shape = (1010,785)\n",
    "X7_test = (np.insert(X7_test,0,1,axis=0)).transpose() #shape = (1028,785)\n",
    "t3 = np.zeros([1,n3])[0] #length = 6131\n",
    "t7 = np.ones([1,n7])[0] #length = 6265\n",
    "t3_test = np.zeros([1,n3_test])[0] #length = 1010\n",
    "t7_test = np.ones([1,n7_test])[0] #length = 1028\n",
    "\n",
    "#These are the important matrices and arrays in the end. X3 consists of P=6131 images of the number 3. X[3] for example is the 4th image. Each image has 28x28=784 pixels. To make sure that an image doesn't only consists of zeros, before each image is a 1 added. \n",
    "X = np.concatenate([X3,X7]) #shape = (12396,785)\n",
    "t = np.concatenate([t3,t7]) #shape = (12396,)\n",
    "X_test = np.concatenate([X3_test,X7_test]) #shape = (2038,785)\n",
    "t_test = np.concatenate([t3_test,t7_test]) #shape = (2038,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#these are the functions that are defined in the exercise \n",
    "\n",
    "def y(w,X): #this function takes a random w and a matrix with N patterns and d dimensions (in our case 785 pixels in total) and returns an array that contains for each pattern the probability that the number is a 3 (or 7)\n",
    "    y = 1/(1+exp(-dot(X,w)))\n",
    "    return y \n",
    "\n",
    "def E(w,X,t): #Return the error for w,X and the actual value 3,7 (so actual 1,0)\n",
    "    y0 = y(w,X)\n",
    "    Ew = -sum(t*log(y0)+(1-t)*log(1-y0))/len(X)\n",
    "    return Ew\n",
    "\n",
    "def dE(w,X,t): #gradient for w,X,t\n",
    "    y0 = y(w,X)\n",
    "    dE = matmul((y0-t),X)/len(X)\n",
    "    return dE\n",
    "\n",
    "def H(w,X): #Hessian for w,X\n",
    "    y0 = y(w,X) \n",
    "    X_y = transpose(multiply(transpose(X),y0*(1-y0))) #multiply each pattern in X by the y value of that pattern. This results in a matrix. \n",
    "    H = matmul(transpose(X_y),X)/len(X) #multiply this X*y times X, and sum over all patterns. The new shape is then (785,785)\n",
    "    return H\n",
    "\n",
    "def dE_weight_decay(w,X,t,k): #Gradient for the weight decay excercises\n",
    "    y0 = y(w,X)\n",
    "    dE = matmul((y0-t),X)/len(X)+k/len(w)*w\n",
    "    return dE\n",
    "\n",
    "def H_weight_decay(w,X,k): #Hessian for the weight decay exercises\n",
    "    y0 = y(w,X) \n",
    "    X_y = transpose(multiply(transpose(X),y0*(1-y0))) #multiply each pattern in X by the y value of that pattern. This results in a matrix. \n",
    "    H = matmul(transpose(X_y),X)/len(X) + k/len(w)*np.eye(len(w)) #multiply this X*y times X, and sum over all patterns. The new shape is then (785,785)\n",
    "    return H\n",
    "\n",
    "def E_stochastic_gradient_descent(w,X,t,div_factor): #Takes already divided X and t. \n",
    "    Ew = np.sum([E(w,X[i],t[i]) for i in range(div_factor)])\n",
    "    return Ew\n",
    "\n",
    "\n",
    "\n",
    "#These are other helpful functions\n",
    "\n",
    "def wrong_patterns(w,X,t): #Takes a model w, a dataset X and labels t and return the fraction of misclassified patterns\n",
    "    y0 = y(w,X)\n",
    "    classifications = np.where(y0>0.5,1,0)\n",
    "    wrong_predictions = np.sum(classifications!=t)\n",
    "    wrong_fraction = wrong_predictions/len(X)\n",
    "    return wrong_fraction\n",
    "\n",
    "\n",
    "def visualize(w,X,i): #Takes a model w, a dataset X and a image number and visualizes the image with what the model thinks it represents\n",
    "    digit = int(np.where(y(w,X[i])>0.5,7,3))\n",
    "    plt.imshow(X[i][1:].reshape(28,28))\n",
    "    return digit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#These are the learning algorithms for the exercise \n",
    "\n",
    "def grad_descent(w0,X,t,e,runs): #e=learning_rate\n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    for i in range(runs):\n",
    "        w += -e*dE(w,X,t)\n",
    "        if i%100==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "    return w\n",
    "\n",
    "def momentum(w0,X,t,e,a,runs): #e=learning_rate, a=momentum_strength, \n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    dw_old = 0\n",
    "    for i in range(runs):\n",
    "        dw_new = -e*dE(w,X,t) + a*dw_old\n",
    "        w += dw_new + dw_old\n",
    "        dw_old = dw_new.copy()\n",
    "        if i%100==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "    return w\n",
    "\n",
    "def weight_decay(w0,X,t,e,a,k,runs): #e=learning_rate, a=momentum_strength, k=weight_decay_factor\n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    dw_old = 0\n",
    "    for i in range(runs):\n",
    "        dw_new = -e*dE(w,X,t) + a*dw_old\n",
    "        w += dw_new + dw_old\n",
    "        dw_old = dw_new.copy()\n",
    "        if i%100==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "    return w\n",
    "\n",
    "def newton_method(w0,X,t,e,a,k,runs): #e=learning_rate, a=momentum_strength, k=weight_decay_factor\n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    for i in range(runs):\n",
    "        w += -np.matmul(inv(H_weight_decay(w,X,t,k)),dE_weight_decay(w,X,t,k))\n",
    "        if i%1==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "    return w\n",
    "\n",
    "def line_search(w,X,t,runs):\n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    for i in range(runs):\n",
    "        d = -dE(w,X,t)\n",
    "        errors = np.array([E(w+i*d,X,t) for i in np.linspace(0.05,1.5,30)]) #create array with all errors for a certain gammas. \n",
    "        min_error = np.where(errors == np.min(errors))[0][0] #find the index of the minimal error. \n",
    "        g = np.linspace(0.05,1.5,30)[min_error] \n",
    "        w += g*d\n",
    "        if i%10==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "    return w\n",
    "\n",
    "def conjugate_gradient_descent(w,X,t,runs):\n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    w_old = w.copy()\n",
    "    d = -dE(w,X,t)\n",
    "    for i in range(runs):\n",
    "        b = dot(dE(w,X,t)-dE(w_old,X,t),dE(w,X,t))/np.dot(dE(w_old,X,t),dE(w_old,X,t))\n",
    "        d = -dE(w,X,t) + b*d\n",
    "        errors = np.array([E(w+i*d,X,t) for i in np.linspace(0.05,0.9,30)]) #create array with all errors for a certain gammas. \n",
    "        min_error = np.where(errors == np.min(errors))[0][0] #find the index of the minimal error. \n",
    "        g = np.linspace(0.05,0.9,30)[min_error] \n",
    "        w_old = w.copy()\n",
    "        w += g*d\n",
    "        if i%10==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "            print(g)\n",
    "    return w\n",
    "\n",
    "def stochastic_gradient_descent(w0,X0,t0,e,div_factor,runs): \n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    X = X0.copy()\n",
    "    t = t0.copy()\n",
    "    Xi = np.array(np.array_split(X,div_factor),dtype=object)\n",
    "    ti = np.array(np.array_split(t,div_factor),dtype=object)\n",
    "    for i in range(runs):\n",
    "        w += -e*np.sum([dE(w,Xi[k],ti[k]) for k in range(div_factor)])\n",
    "        if i%100==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E_stochastic_gradient_descent(w,X,t,div_factor),3)))\n",
    "    return w\n",
    "\n",
    "\n",
    "\n",
    "#This is executing the script \n",
    "w0 = np.random.normal(0,1,size=X.shape[1]) #initializing a random model w0 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:68: RuntimeWarning: overflow encountered in exp\n",
      "ipykernel_launcher:73: RuntimeWarning: divide by zero encountered in log\n",
      "ipykernel_launcher:73: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.3s E=nan\n",
      "100 2.1s E=1.561\n",
      "200 4.1s E=nan\n",
      "300 5.9s E=0.0\n",
      "400 7.7s E=inf\n",
      "500 9.5s E=0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-556-b736a761ccf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw_stochastic_gradient_descent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstochastic_gradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiv_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#learning the model via weight decay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresults_stochastic_gradient_descent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_stochastic_gradient_descent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrong_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_stochastic_gradient_descent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_stochastic_gradient_descent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mwrong_patterns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_stochastic_gradient_descent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-546-011de9be41d7>\u001b[0m in \u001b[0;36mstochastic_gradient_descent\u001b[0;34m(w0, X0, t0, e, div_factor, runs)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiv_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiv_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mT2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-546-011de9be41d7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mti\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiv_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mruns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mti\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiv_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mT2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-546-011de9be41d7>\u001b[0m in \u001b[0;36mdE\u001b[0;34m(w, X, t)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#gradient for w,X,t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0my0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mdE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "w_stochastic_gradient_descent = stochastic_gradient_descent(w0,X,t,e=0.001,div_factor=100,runs=1000) #learning the model via weight decay \n",
    "results_stochastic_gradient_descent = [[E(w_stochastic_gradient_descent,X,t),wrong_patterns(w_stochastic_gradient_descent,X,t)],[E(w_stochastic_gradient_descent,X_test,t_test),wrong_patterns(w_stochastic_gradient_descent,X_test,t_test)]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ipykernel_launcher:68: RuntimeWarning: overflow encountered in exp\n",
      "ipykernel_launcher:73: RuntimeWarning: divide by zero encountered in log\n",
      "ipykernel_launcher:73: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.2s E=nan\n"
     ]
    }
   ],
   "source": [
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    div_factor = 100\n",
    "    e = 0.05\n",
    "    runs = 100\n",
    "    \n",
    "    Xi = np.array(np.array_split(X,div_factor),dtype=object)\n",
    "    ti = np.array(np.array_split(t,div_factor),dtype=object)\n",
    "    for i in range(runs):\n",
    "        w += -e*np.sum([dE(w,Xi[k],ti[k]) for k in range(div_factor)])\n",
    "        if i%100==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E_stochastic_gradient_descent(w,X,t,div_factor),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-264.20865794, -265.66915794, -263.25853675, -265.6079144 ,\n",
       "       -265.06015485, -265.3948144 , -266.36556364, -265.38632324,\n",
       "       -265.51046774, -265.4967352 , -265.53792246, -264.83504435,\n",
       "       -265.61930182, -264.48338833, -264.35047999, -265.38850525,\n",
       "       -264.98341123, -265.4085046 , -266.08474104, -264.14236655,\n",
       "       -266.21161899, -264.72505393, -264.91183796, -265.72568746,\n",
       "       -265.31079155, -264.35679225, -264.9589747 , -265.73621858,\n",
       "       -267.32709771, -265.8642513 , -266.32144639, -264.76509643,\n",
       "       -267.34611446, -264.70765287, -265.30975742, -263.93928476,\n",
       "       -265.5277897 , -264.06170387, -266.09570398, -264.44540161,\n",
       "       -265.63239323, -265.68526193, -263.92889474, -265.55338136,\n",
       "       -266.99219448, -265.41480627, -264.89843778, -264.67059094,\n",
       "       -265.31120376, -265.21459757, -263.23463863, -266.30784155,\n",
       "       -265.95258114, -264.69387853, -264.27152455, -265.61990895,\n",
       "       -265.80695376, -265.2286823 , -264.8516005 , -265.33170627,\n",
       "       -265.3224673 , -264.34389993, -264.87336683, -265.20214897,\n",
       "       -265.58647309, -265.5729248 , -265.26342523, -265.8894513 ,\n",
       "       -266.19715208, -264.19336339, -264.90331645, -265.20770765,\n",
       "       -266.77916959, -265.98020401, -263.94142394, -264.14518004,\n",
       "       -264.71437394, -263.48581139, -265.75388966, -265.25001201,\n",
       "       -263.69766588, -265.53007304, -265.26104819, -265.0386832 ,\n",
       "       -263.75236958, -266.63747624, -265.78573515, -265.01289244,\n",
       "       -265.6383001 , -264.68928963, -266.12798333, -264.68499166,\n",
       "       -265.9029773 , -265.95016569, -263.9227377 , -266.07764852,\n",
       "       -265.17396243, -265.29582118, -264.99361522, -264.45896806,\n",
       "       -265.4793736 , -263.71258838, -265.64698384, -266.01468633,\n",
       "       -265.51867079, -266.07289429, -265.11827414, -266.07182876,\n",
       "       -264.57923158, -266.92713075, -265.64703541, -264.25184247,\n",
       "       -265.05539637, -264.92460196, -264.92388728, -264.36972507,\n",
       "       -265.97404079, -262.93505805, -266.86471319, -264.42337015,\n",
       "       -263.15713247, -265.58757281, -266.10102862, -265.7149845 ,\n",
       "       -263.71511146, -267.64468887, -263.96322082, -267.30386452,\n",
       "       -265.90453282, -264.9871073 , -267.3128357 , -263.99235176,\n",
       "       -264.30371524, -266.89998519, -266.62184366, -266.462231  ,\n",
       "       -264.26607685, -265.05538689, -266.32339773, -265.24184298,\n",
       "       -263.95436672, -264.41239554, -264.12022048, -267.29188811,\n",
       "       -264.06984517, -265.28506638, -265.4648262 , -263.79354098,\n",
       "       -263.93387299, -264.88821876, -265.9056348 , -265.25484384,\n",
       "       -263.95900439, -265.239249  , -264.86310544, -263.29671251,\n",
       "       -263.85708185, -266.18041749, -264.51602169, -266.13979791,\n",
       "       -265.29826435, -264.58677228, -263.85163804, -263.529976  ,\n",
       "       -264.47168031, -264.62736726, -263.52497901, -265.22140237,\n",
       "       -263.7708605 , -265.37605486, -263.2710903 , -266.26652894,\n",
       "       -264.03074014, -263.82885464, -265.17541207, -264.22498875,\n",
       "       -263.7774741 , -265.76984472, -265.97490051, -264.1096616 ,\n",
       "       -264.39944807, -264.5100667 , -264.58260807, -265.61033967,\n",
       "       -263.75702893, -265.63083688, -265.73853043, -265.6016996 ,\n",
       "       -262.42549522, -266.5013242 , -263.54817374, -265.29135507,\n",
       "       -266.35477827, -264.75497947, -265.12196562, -265.83581592,\n",
       "       -265.55224213, -265.04848285, -265.61740788, -265.61778371,\n",
       "       -264.66752376, -265.34026898, -265.79721716, -265.61137152,\n",
       "       -264.3210135 , -265.11549212, -265.82625007, -265.68413802,\n",
       "       -264.02268903, -265.2184226 , -266.44663308, -264.83763452,\n",
       "       -265.4984945 , -262.87463348, -264.54024641, -266.24853728,\n",
       "       -263.57114713, -264.70724026, -265.13898329, -265.39549001,\n",
       "       -266.33058005, -265.6064898 , -265.24307278, -264.55175525,\n",
       "       -264.2734551 , -265.47936297, -263.31761671, -264.30060251,\n",
       "       -264.85400766, -262.6608428 , -266.64401281, -265.78737382,\n",
       "       -264.15056404, -265.11982119, -264.94015494, -265.10309805,\n",
       "       -266.53315974, -264.87878002, -264.48988009, -266.95127355,\n",
       "       -265.74940018, -265.86919538, -265.98721997, -264.46877782,\n",
       "       -266.13096013, -266.0163839 , -266.19617762, -264.67558499,\n",
       "       -265.92945407, -265.43900019, -266.22435809, -265.00289901,\n",
       "       -263.13117789, -265.38794503, -265.44597828, -263.38408454,\n",
       "       -264.01151666, -262.81747085, -264.32790172, -264.49195573,\n",
       "       -265.0855957 , -265.57129195, -266.57786237, -264.17031251,\n",
       "       -265.55414231, -263.30651123, -265.41231906, -265.87234175,\n",
       "       -266.35425553, -265.92357987, -264.86397965, -264.7561693 ,\n",
       "       -265.05049629, -266.5586994 , -266.12076149, -266.22195464,\n",
       "       -265.0485492 , -264.49553475, -265.91045533, -264.27740976,\n",
       "       -266.02494917, -266.51503955, -265.92119973, -264.86639428,\n",
       "       -264.45911865, -264.21607637, -264.20093927, -264.87167323,\n",
       "       -265.58332421, -264.97753894, -264.13435506, -265.68076701,\n",
       "       -264.61106691, -265.47481545, -265.76268271, -266.25916266,\n",
       "       -265.15609151, -263.91604099, -265.73915392, -263.47794002,\n",
       "       -264.43972431, -263.87617879, -266.14812707, -263.63387785,\n",
       "       -267.66115112, -263.62851587, -265.66185706, -264.26322659,\n",
       "       -265.5491477 , -265.71118054, -264.62523052, -263.95399146,\n",
       "       -263.92956432, -267.92227465, -262.860498  , -265.13950578,\n",
       "       -266.64391864, -264.00354923, -264.13522122, -266.23992995,\n",
       "       -266.44815007, -266.61619633, -264.05762545, -264.19549836,\n",
       "       -264.00114726, -266.03416582, -265.2957381 , -264.86959525,\n",
       "       -265.43816642, -267.71751739, -266.21438075, -264.93925303,\n",
       "       -265.78036143, -265.209599  , -266.28738281, -265.3894399 ,\n",
       "       -265.63631014, -266.13236763, -265.41882305, -262.86646758,\n",
       "       -263.60905598, -265.55194929, -264.96807028, -265.62171861,\n",
       "       -265.18168622, -266.54417969, -266.31789407, -264.14034587,\n",
       "       -265.04450707, -265.83230077, -264.45767802, -265.36547224,\n",
       "       -264.42456651, -264.52343688, -266.19967475, -263.90011738,\n",
       "       -265.65482405, -263.99122335, -266.60808586, -264.55447663,\n",
       "       -266.72395206, -265.09135094, -264.35052149, -264.46941284,\n",
       "       -264.61418983, -263.79005794, -264.05455892, -265.87596994,\n",
       "       -265.61496307, -264.88238709, -266.72815772, -265.54795336,\n",
       "       -264.14523752, -263.50595728, -264.38452686, -265.71354977,\n",
       "       -266.340414  , -266.3831427 , -265.23466436, -264.25589589,\n",
       "       -263.06135373, -266.30001798, -264.7480633 , -264.86045498,\n",
       "       -263.59246649, -265.42142315, -266.48700294, -265.6085045 ,\n",
       "       -265.27805385, -264.82808437, -265.19615689, -265.47194587,\n",
       "       -265.40317104, -266.82036374, -266.31780736, -264.59867964,\n",
       "       -266.46488003, -263.54813546, -265.51754051, -266.05718195,\n",
       "       -264.78242932, -264.67349778, -264.22688526, -264.66399093,\n",
       "       -264.10407852, -264.81518073, -265.41223939, -264.97896376,\n",
       "       -266.21581661, -264.19776878, -265.25653351, -265.57239616,\n",
       "       -265.17262082, -265.27253157, -265.00471508, -266.07122293,\n",
       "       -265.59057877, -264.73422955, -265.0657702 , -264.91487017,\n",
       "       -265.94505991, -265.48462714, -263.59696576, -264.46636498,\n",
       "       -264.61605253, -265.68378015, -263.13298669, -263.91149883,\n",
       "       -266.23159312, -264.19983907, -264.63978234, -265.72215094,\n",
       "       -265.28906283, -265.73263135, -265.71259767, -267.52371224,\n",
       "       -264.29377481, -264.17401855, -264.93801785, -263.75813188,\n",
       "       -264.7958609 , -264.45048164, -264.51144401, -264.51542793,\n",
       "       -265.85761074, -264.56716511, -263.12462478, -265.1373565 ,\n",
       "       -264.88506469, -264.84897327, -264.3380312 , -264.79274636,\n",
       "       -264.92275156, -264.56292552, -265.93715727, -264.72415824,\n",
       "       -264.14402638, -266.20683068, -265.05766077, -264.41845609,\n",
       "       -264.74542887, -265.32847065, -265.28943829, -266.19993978,\n",
       "       -264.32193642, -264.3166685 , -266.33575205, -263.22319693,\n",
       "       -266.3455685 , -265.85386031, -265.02883004, -264.06715482,\n",
       "       -264.24215251, -263.0541246 , -265.07188482, -263.1427499 ,\n",
       "       -265.0666081 , -265.27964626, -263.56288737, -265.11159332,\n",
       "       -266.46323955, -264.53163551, -266.92342843, -264.27278004,\n",
       "       -266.1293415 , -263.41109082, -262.89577416, -265.50198969,\n",
       "       -264.20096636, -263.98638352, -265.01816606, -265.35445917,\n",
       "       -265.80139627, -264.88374372, -264.18261366, -266.48737653,\n",
       "       -264.40273264, -265.7857081 , -265.23671609, -264.64394121,\n",
       "       -265.87740399, -265.22996349, -266.20925943, -264.33955199,\n",
       "       -265.04496981, -265.1877219 , -266.12051079, -264.35571478,\n",
       "       -265.65194287, -264.30544772, -265.90400115, -267.86584234,\n",
       "       -264.20643687, -266.88720038, -264.16047044, -264.20012689,\n",
       "       -265.42267255, -264.710193  , -265.98962534, -265.85906523,\n",
       "       -263.7750487 , -265.12651041, -265.51744065, -265.55400047,\n",
       "       -266.23899833, -265.5133523 , -266.94256369, -267.2079589 ,\n",
       "       -264.79866987, -264.56556321, -265.0730871 , -266.44913084,\n",
       "       -265.47803506, -266.11524291, -265.55202568, -266.38973695,\n",
       "       -266.76382303, -263.84166893, -266.02458169, -264.84546704,\n",
       "       -265.28487259, -264.47528248, -264.86515506, -264.95364476,\n",
       "       -263.85939889, -266.02723809, -265.74568417, -265.21101086,\n",
       "       -264.79058642, -264.84029515, -265.12035752, -265.51258948,\n",
       "       -263.78020183, -265.03756712, -263.60050862, -265.61277774,\n",
       "       -265.63322551, -264.9206475 , -265.69411156, -264.33597327,\n",
       "       -264.47626031, -264.93227597, -263.66406048, -267.2570005 ,\n",
       "       -265.44595151, -265.03478391, -265.08222001, -266.99120815,\n",
       "       -264.07656357, -265.84285475, -266.74713565, -265.07313296,\n",
       "       -266.44782004, -264.89546387, -263.38657129, -264.78649276,\n",
       "       -266.4242529 , -264.50444031, -264.58043878, -264.53372396,\n",
       "       -265.18426193, -265.73704659, -264.63268709, -265.89853898,\n",
       "       -264.46991873, -264.73232507, -265.58734145, -263.97823901,\n",
       "       -266.41361652, -265.83764377, -265.87556238, -264.45048894,\n",
       "       -266.01687784, -265.92364142, -264.68662101, -264.56412773,\n",
       "       -266.10122917, -263.55619711, -264.99000928, -265.17578139,\n",
       "       -264.75742013, -264.854262  , -263.1375983 , -265.20627398,\n",
       "       -264.08483741, -266.5104002 , -265.96945602, -264.60730696,\n",
       "       -266.00889525, -265.31588213, -263.75294837, -265.54156698,\n",
       "       -264.32519702, -266.74863867, -264.32320113, -265.26646865,\n",
       "       -266.55602928, -266.78510822, -265.16114135, -265.34097482,\n",
       "       -265.67074447, -264.76938378, -265.91536865, -266.03562413,\n",
       "       -266.60532326, -265.81266218, -267.01198123, -264.77436631,\n",
       "       -266.01232692, -265.79126371, -265.01376363, -264.572739  ,\n",
       "       -265.83386574, -265.33455826, -264.65722333, -264.62518132,\n",
       "       -264.80931438, -264.56604722, -265.45305966, -266.26891736,\n",
       "       -265.75476107, -266.12787309, -265.59939424, -266.08811427,\n",
       "       -265.83215884, -265.14671141, -266.43582371, -266.69004046,\n",
       "       -264.79387076, -265.20295967, -263.86902018, -265.79712072,\n",
       "       -265.27428528, -265.52650605, -266.90072416, -264.49987137,\n",
       "       -265.38478462, -265.1144032 , -264.11218435, -266.85395864,\n",
       "       -264.48695843, -263.09288012, -266.57768062, -265.29775393,\n",
       "       -265.06028516, -264.9448575 , -264.15796719, -266.14776671,\n",
       "       -265.34178193, -266.72121021, -264.01320035, -264.30333065,\n",
       "       -266.65634899, -266.08808815, -265.23570302, -266.76317917,\n",
       "       -266.41009377, -265.85851653, -263.57693036, -264.83870503,\n",
       "       -263.34686703, -266.94841179, -265.75415227, -264.48143345,\n",
       "       -265.32806276, -265.69598609, -265.52721861, -265.9592746 ,\n",
       "       -263.15828761, -265.63542897, -263.91815031, -267.16258269,\n",
       "       -264.71555157, -264.60502552, -265.52871758, -266.72341331,\n",
       "       -266.08873058, -264.88803749, -263.21093944, -264.88135672,\n",
       "       -264.72834602, -264.36636801, -264.39981708, -264.81637777,\n",
       "       -264.87715652, -265.92713719, -263.99650975, -263.6937269 ,\n",
       "       -265.81129085, -267.42364116, -266.77919133, -266.91665297,\n",
       "       -264.1605539 , -264.65471831, -264.74603584, -264.06479986,\n",
       "       -263.95978558, -263.48386733, -267.46879432, -265.32213455,\n",
       "       -263.3053293 , -265.5447334 , -264.86334295, -265.69686255,\n",
       "       -266.80012542, -264.39432079, -265.81312675, -265.80608829,\n",
       "       -265.6548302 , -266.32785234, -265.70718459, -265.71390706,\n",
       "       -266.20974381, -265.81999941, -266.33552897, -263.98506084,\n",
       "       -266.01935312, -265.22868984, -265.28649601, -265.9058958 ,\n",
       "       -264.28003182, -263.45936029, -266.2187351 , -265.97778959,\n",
       "       -264.6045608 , -264.69575662, -265.26139403, -264.91278866,\n",
       "       -265.16843613, -263.82362187, -265.06683748, -266.23632529,\n",
       "       -264.46171637, -265.5807053 , -265.76879351, -266.14300898,\n",
       "       -265.96933381, -266.62975351, -264.41657955, -265.47426741,\n",
       "       -263.90266553, -263.06298741, -263.92245521, -266.20071349,\n",
       "       -265.56011127, -265.93895701, -264.67883056, -265.74670666,\n",
       "       -265.90518142, -264.10742427, -266.34163967, -265.25494175,\n",
       "       -264.4918447 , -266.19080328, -265.4408533 , -264.99579435,\n",
       "       -264.69229084, -264.06535269, -265.76123215, -265.0971162 ,\n",
       "       -264.39310811, -265.50559687, -263.69159197, -265.96034424,\n",
       "       -265.48007244])"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4aedca058b4155234967fa3da88bf0b29abe2f47d758f3debe6af85bc2e061a5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
