{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import sum \n",
    "from numpy import matmul\n",
    "from numpy import multiply\n",
    "from numpy import dot\n",
    "from numpy import exp\n",
    "from numpy import log\n",
    "from numpy import abs\n",
    "from numpy import min\n",
    "from numpy import transpose\n",
    "from numpy.core.function_base import linspace\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy import optimize\n",
    "import time\n",
    "\n",
    "#Loading in the MNIST data\n",
    "file = loadmat('/Users/samsuidman/Desktop/neurophysics/machine_learning/mnistAll.mat') \n",
    "\n",
    "#Preparing the data\n",
    "train_images = file['mnist']['train_images'][0][0]\n",
    "train_labels = file['mnist']['train_labels'][0][0].transpose()[0]\n",
    "test_images = file['mnist']['test_images'][0][0]\n",
    "test_labels = file['mnist']['test_labels'][0][0].transpose()[0]\n",
    "indices_3 = np.where(train_labels==3)[0]\n",
    "indices_7 = np.where(train_labels==7)[0]\n",
    "indices_3_test = np.where(test_labels==3)[0]\n",
    "indices_7_test = np.where(test_labels==7)[0]\n",
    "X3 = train_images[:,:,indices_3]\n",
    "X7 = train_images[:,:,indices_7]\n",
    "X3_test = test_images[:,:,indices_3_test]\n",
    "X7_test = test_images[:,:,indices_7_test]\n",
    "n3 = np.size(X3,2)\n",
    "n7 = np.size(X7,2)\n",
    "n3_test = np.size(X3_test,2)\n",
    "n7_test = np.size(X7_test,2)\n",
    "X3 = np.reshape(X3,[784,n3])\n",
    "X7 = np.reshape(X7,[784,n7])\n",
    "X3_test = np.reshape(X3_test,[784,n3_test])\n",
    "X7_test = np.reshape(X7_test,[784,n7_test])\n",
    "X3 = X3/np.max((np.max(np.concatenate(X3)),np.max(np.concatenate(X7))))\n",
    "X7 = X7/np.max((np.max(np.concatenate(X3)),np.max(np.concatenate(X7))))\n",
    "X3_test = X3_test/np.max((np.max(np.concatenate(X3_test)),np.max(np.concatenate(X7_test))))\n",
    "X7_test = X7_test/np.max((np.max(np.concatenate(X3_test)),np.max(np.concatenate(X7_test))))\n",
    "X3 = (np.insert(X3,0,1,axis=0)).transpose() #shape = (6131,785)\n",
    "X7 = (np.insert(X7,0,1,axis=0)).transpose() #shape = (6265,785)\n",
    "X3_test = (np.insert(X3_test,0,1,axis=0)).transpose() #shape = (1010,785)\n",
    "X7_test = (np.insert(X7_test,0,1,axis=0)).transpose() #shape = (1028,785)\n",
    "t3 = np.zeros([1,n3])[0] #length = 6131\n",
    "t7 = np.ones([1,n7])[0] #length = 6265\n",
    "t3_test = np.zeros([1,n3_test])[0] #length = 1010\n",
    "t7_test = np.ones([1,n7_test])[0] #length = 1028\n",
    "\n",
    "#These are the important matrices and arrays in the end. X3 consists of P=6131 images of the number 3. X[3] for example is the 4th image. Each image has 28x28=784 pixels. To make sure that an image doesn't only consists of zeros, before each image is a 1 added. \n",
    "X = np.concatenate([X3,X7]) #shape = (12396,785)\n",
    "t = np.concatenate([t3,t7]) #shape = (12396,)\n",
    "X_test = np.concatenate([X3_test,X7_test]) #shape = (2038,785)\n",
    "t_test = np.concatenate([t3_test,t7_test]) #shape = (2038,)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#these are the functions that are defined in the exercise \n",
    "\n",
    "def y(w,X): #this function takes a random w and a matrix with N patterns and d dimensions (in our case 785 pixels in total) and returns an array that contains for each pattern the probability that the number is a 3 (or 7)\n",
    "    y = 1/(1+exp(-dot(X,w)))\n",
    "    return y \n",
    "\n",
    "def E(w,X,t): #Return the error for w,X and the actual value 3,7 (so actual 1,0)\n",
    "    y0 = y(w,X)\n",
    "    Ew = -sum(t*log(y0)+(1-t)*log(1-y0))/len(X)\n",
    "    return Ew\n",
    "\n",
    "def dE(w,X,t): #gradient for w,X,t\n",
    "    y0 = y(w,X)\n",
    "    dE = matmul((y0-t),X)/len(X)\n",
    "    return dE\n",
    "\n",
    "def H(w,X): #Hessian for w,X\n",
    "    y0 = y(w,X) \n",
    "    X_y = transpose(multiply(transpose(X),y0*(1-y0))) #multiply each pattern in X by the y value of that pattern. This results in a matrix. \n",
    "    H = matmul(transpose(X_y),X)/len(X) #multiply this X*y times X, and sum over all patterns. The new shape is then (785,785)\n",
    "    return H\n",
    "\n",
    "def dE_weight_decay(w,X,t,k): #Gradient for the weight decay excercises\n",
    "    y0 = y(w,X)\n",
    "    dE = matmul((y0-t),X)/len(X)+k/len(w)*w\n",
    "    return dE\n",
    "\n",
    "def H_weight_decay(w,X,k): #Hessian for the weight decay exercises\n",
    "    y0 = y(w,X) \n",
    "    X_y = transpose(multiply(transpose(X),y0*(1-y0))) #multiply each pattern in X by the y value of that pattern. This results in a matrix. \n",
    "    H = matmul(transpose(X_y),X)/len(X) + k/len(w)*np.eye(len(w)) #multiply this X*y times X, and sum over all patterns. The new shape is then (785,785)\n",
    "    return H\n",
    "\n",
    "X_line_search = X.copy()\n",
    "t_line_search = t.copy()\n",
    "def E_line_search(w): #Return the error for w,X and the actual value 3,7 (so actual 1,0)\n",
    "    y0 = 1/(1+np.exp(-np.dot(X_line_search,w)))\n",
    "    Ew = -sum(t_line_search*log(y0)+(1-t_line_search)*log(1-y0))/len(X_line_search)\n",
    "    return Ew\n",
    "\n",
    "def dE_line_search(w): #gradient for w,X,t\n",
    "    y0 = 1/(1+np.exp(-np.dot(X_line_search,w)))\n",
    "    dE = matmul((y0-t_line_search),X_line_search)/len(X_line_search)\n",
    "    return dE\n",
    "\n",
    "\n",
    "\n",
    "#These are other helpful functions\n",
    "\n",
    "def wrong_patterns(w,X,t): #Takes a model w, a dataset X and labels t and return the fraction of misclassified patterns\n",
    "    y0 = y(w,X)\n",
    "    classifications = np.where(y0>0.5,1,0)\n",
    "    wrong_predictions = np.sum(classifications!=t)\n",
    "    wrong_fraction = wrong_predictions/len(X)\n",
    "    return wrong_fraction\n",
    "\n",
    "\n",
    "def visualize(w,X,i): #Takes a model w, a dataset X and a image number and visualizes the image with what the model thinks it represents\n",
    "    digit = int(np.where(y(w,X[i])>0.5,7,3))\n",
    "    plt.imshow(X[i][1:].reshape(28,28))\n",
    "    return digit\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#These are the learning algorithms for the exercise \n",
    "\n",
    "def grad_descent(w0,X,t,e,runs): #e=learning_rate\n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    for i in range(runs):\n",
    "        w += -e*dE(w,X,t)\n",
    "        if i%100==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "    return w\n",
    "\n",
    "def momentum(w0,X,t,e,a,runs): #e=learning_rate, a=momentum_strength, \n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    dw_old = 0\n",
    "    for i in range(runs):\n",
    "        dw_new = -e*dE(w,X,t) + a*dw_old\n",
    "        w += dw_new + dw_old\n",
    "        dw_old = dw_new.copy()\n",
    "        if i%100==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "    return w\n",
    "\n",
    "def weight_decay(w0,X,t,e,a,k,runs): #e=learning_rate, a=momentum_strength, k=weight_decay_factor\n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    dw_old = 0\n",
    "    for i in range(runs):\n",
    "        dw_new = -e*dE(w,X,t) + a*dw_old\n",
    "        w += dw_new + dw_old\n",
    "        dw_old = dw_new.copy()\n",
    "        if i%100==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "    return w\n",
    "\n",
    "def newton_method(w0,X,t,e,a,k,runs): #e=learning_rate, a=momentum_strength, k=weight_decay_factor\n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    for i in range(runs):\n",
    "        w += -np.matmul(inv(H_weight_decay(w,X,t,k)),dE_weight_decay(w,X,t,k))\n",
    "        if i%1==0: \n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "    return w\n",
    "\n",
    "def line_search(w1,X,t,runs):\n",
    "    T1 = time.time()\n",
    "    w = w1.copy()\n",
    "    for i in range(runs):\n",
    "        d = -dE_line_search(w)\n",
    "        g = optimize.line_search(E_line_search,dE_line_search,w,d)[0]\n",
    "        w += g*d\n",
    "        if i%10==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "    return w\n",
    "\n",
    "\n",
    "def conjugate_gradient_descent(w,X,t,runs):\n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    w_old = w.copy()\n",
    "    d = -dE(w,X,t)\n",
    "    for i in range(runs):\n",
    "        b = dot(dE(w,X,t)-dE(w_old,X,t),dE(w,X,t))/np.dot(dE(w_old,X,t),dE(w_old,X,t))\n",
    "        d = -dE(w,X,t) + b*d\n",
    "        errors = np.array([E(w+i*d,X,t) for i in np.linspace(0.05,0.9,30)]) #create array with all errors for a certain gammas. \n",
    "        min_error = np.where(errors == np.min(errors))[0][0] #find the index of the minimal error. \n",
    "        g = np.linspace(0.05,0.9,30)[min_error] \n",
    "        w_old = w.copy()\n",
    "        w += g*d\n",
    "        if i%10==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "            print(g)\n",
    "    return w\n",
    "\n",
    "def stochastic_gradient_descent(w0,X0,t0,e,div_factor,runs): \n",
    "    T1 = time.time()\n",
    "    w = w0.copy()\n",
    "    Xi = np.array(np.array_split(X,div_factor),dtype=object)\n",
    "    ti = np.array(np.array_split(t,div_factor),dtype=object)\n",
    "    for i in range(runs):\n",
    "        j = np.random.randint(0,div_factor)\n",
    "        w += -e*dE(w,Xi[j],ti[j]) #waarschijnlijk gaat het in deze stap fout, omdat de som van al die gradient descent termen heel groot is. \n",
    "        if i%100==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3))) #Ook kijken naar de errorfunctie \n",
    "    return w\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#This is executing the script \n",
    "w0 = np.random.normal(0,1,size=X.shape[1]) #initializing a random model w0 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_search(w1,X,t,runs):\n",
    "    T1 = time.time()\n",
    "    w = w1.copy()\n",
    "    for i in range(runs):\n",
    "        d = -dE_line_search(w)\n",
    "        g = optimize.line_search(E_line_search,dE_line_search,w,d)[0]\n",
    "        w += g*d\n",
    "        if i%10==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "    return w\n",
    "\n",
    "def conjugate_gradient_descent(w1,X,t,runs):\n",
    "    T1 = time.time()\n",
    "    w_old = w1.copy() #initialize both on w_old and w(=w_new) on the w1 that you start with \n",
    "    w = w1.copy()\n",
    "    d = 0 #initialize d as 0 such that d is the gradient descent the first time it is used \n",
    "    for i in range(runs):\n",
    "        b = dot(dE(w,X,t)-dE(w_old,X,t),dE(w,X,t))/np.dot(dE(w_old,X,t),dE(w_old,X,t))\n",
    "        d = -dE(w,X,t) + b*d\n",
    "        g = optimize.line_search(E_line_search,dE_line_search,w,d)[0]\n",
    "        w_old = w.copy()\n",
    "        w += g*d\n",
    "        if i%10==0:\n",
    "            T2 = time.time()\n",
    "            print(i,str(round(T2-T1,1))+'s','E='+str(round(E(w,X,t),3)))\n",
    "            print(g)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4aedca058b4155234967fa3da88bf0b29abe2f47d758f3debe6af85bc2e061a5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
